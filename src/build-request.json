{
  "kind": "build_request",
  "title": "Restore prior video editor behavior and add advanced in-browser audio enhancement controls (noise suppression, transient suppression, voice isolation, spectral repair)",
  "priority": "normal",
  "requirements": [
    {
      "id": "REQ-5",
      "text": "Restore the video editing experience to how it was before the recent audio editor changes, ensuring that video editing UI, controls, preview behavior, and job history video comparison functionality are not altered or degraded by audio-related refactors.",
      "target": "frontend",
      "source": {
        "messageIds": [
          "msg-1"
        ],
        "quotes": [
          "the video editing wasn't suppose to change if the video editing can go back to how it was then"
        ]
      },
      "acceptanceCriteria": [
        "Dashboard > Video Editor tab renders the same video editor UI/interaction model that existed prior to the audio editor changes (no audio-editor UI/copy appearing in video surfaces).",
        "Video job playback, effect toggles/sliders, and preview rendering continue to function without regressions.",
        "History tab: expanding a completed video job still shows VideoComparison and VideoPreviewManager, and users can download the processed video.",
        "No new video-editing behavior changes are introduced as part of implementing audio enhancements."
      ]
    },
    {
      "id": "REQ-6",
      "text": "Implement an advanced audio editing workflow for audio mode that provides user-controllable processing for: heavy background noise suppression, transient/impulse suppression (banging/clicks/knocks), voice/speech isolation (voice separated from other sounds), spectral repair to mitigate speech distortion artifacts, and high/mid/low (multi-band) tone profiling; include real-time preview playback controls and export/download of the edited audio.",
      "target": "frontend",
      "source": {
        "messageIds": [
          "msg-1"
        ],
        "quotes": [
          "implement a very powerful deep learning audio editing as the brain to operate the audio editing with a heavy duty noise reduction to deep suppress background sounds, a very powerful transient shaping element to remove all loud banging sounds and any impulsive sounds,and a very powerful source separation element to separate voice/speech from all other sounds, the ability to playback across all platforms and a very powerful spectral repair element to repair any distorting of speech"
        ]
      },
      "acceptanceCriteria": [
        "Audio mode provides an editor UI with toggles/sliders for (at minimum): Noise Suppression, Transient Suppression, Voice Isolation, Spectral Repair, and a 3-band (Low/Mid/High) tone control.",
        "Users can play/pause, seek/scrub, and A/B preview original vs edited audio inside the app without needing an AI prompt.",
        "Users can export/download the edited result as an audio file.",
        "All user-facing text is in English."
      ]
    },
    {
      "id": "REQ-7",
      "text": "Wire the advanced audio editing workflow into the existing upload/job lifecycle so that running audio processing produces a completed job with the processed blob set, and the job’s applied audio flags (e.g., deepNoiseSuppressionApplied, transientReduction, voiceIsolation, spectralRepair, etc.) reflect the user-selected audio enhancements.",
      "target": "both",
      "source": {
        "messageIds": [
          "msg-1"
        ],
        "quotes": [
          "implement a very powerful deep learning audio editing as the brain to operate the audio editing ... for real-time editing"
        ]
      },
      "acceptanceCriteria": [
        "Starting from Upload (audio mode), a user can apply audio enhancement settings, run processing, and the backend job ends in status=completed with processedFile populated.",
        "The completed job shown in History reflects the applied audio processing via the existing job boolean fields (e.g., deepNoiseSuppressionApplied/transientReduction/voiceIsolation/spectralRepair) where applicable.",
        "Downloading a completed audio job downloads the processed (edited) audio blob, not the original, when processing was run.",
        "Failures in the audio processing pipeline are caught and surfaced to the user as an error state without leaving the UI stuck in a processing state."
      ]
    },
    {
      "id": "REQ-8",
      "text": "Ensure audio playback works reliably across major browsers/platforms by using browser-native audio playback elements for preview (including iOS/Safari constraints) and by avoiding approaches that prevent waveform/spectrum components from attaching to the audio element.",
      "target": "frontend",
      "source": {
        "messageIds": [
          "msg-1"
        ],
        "quotes": [
          "the ability to playback across all platforms"
        ]
      },
      "acceptanceCriteria": [
        "Audio preview uses an in-DOM <audio> element (or an equivalent approach) so existing visualization components can attach reliably.",
        "Audio preview controls work in Chrome, Firefox, and Safari (including basic iOS/Safari autoplay restrictions handled via explicit user interaction).",
        "Waveform/spectrum components initialize successfully when previewing audio from completed jobs."
      ]
    }
  ],
  "constraints": [
    "Backend must remain a single Motoko actor in backend/main.mo; only add backend changes consistent with this architecture.",
    "Do not edit files under frontend immutablePaths (e.g., frontend/src/hooks/useInternetIdentity.ts(x), frontend/src/hooks/useActor.ts, frontend/src/main.tsx, frontend/src/components/ui).",
    "No external AI/LLM service integrations (no OpenAI/Anthropic/etc.) and no third-party auth beyond Internet Identity.",
    "Do not rely on WebSockets or other unsupported real-time server features; keep processing client-side and persist results via existing upload/completeProcessing APIs.",
    "Use English for all user-facing text."
  ],
  "nonGoals": [
    "Implementing true deep-learning model inference, “supreme intelligence,” or guaranteed GPU-accelerated neural processing; the implementation should be limited to feasible in-browser audio processing techniques.",
    "Adding third-party DSP/ML cloud services for source separation or spectral repair.",
    "Changing unrelated application theming/layout beyond what is necessary to restore the video editor and add the requested audio controls."
  ],
  "imageRequirements": {
    "required": [],
    "edits": []
  }
}